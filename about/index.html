<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>About This Work | QuTiBench</title>
<meta name="generator" content="Jekyll v4.0.0" />
<meta property="og:title" content="About This Work" />
<meta property="og:locale" content="en_US" />
<link rel="canonical" href="https://rcl-lab.github.io/Qutibench_Web/about/" />
<meta property="og:url" content="https://rcl-lab.github.io/Qutibench_Web/about/" />
<meta property="og:site_name" content="QuTiBench" />
<script type="application/ld+json">
{"@type":"WebSite","url":"https://rcl-lab.github.io/Qutibench_Web/about/","name":"QuTiBench","headline":"About This Work","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/Qutibench_Web/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://rcl-lab.github.io/Qutibench_Web/feed.xml" title="QuTiBench" /><link rel="shortcut icon" type="image/x-icon" href="/Qutibench_Web/images/favicon.ico"><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>About This Work | QuTiBench</title>
<meta name="generator" content="Jekyll v4.0.0" />
<meta property="og:title" content="About This Work" />
<meta property="og:locale" content="en_US" />
<link rel="canonical" href="https://rcl-lab.github.io/Qutibench_Web/about/" />
<meta property="og:url" content="https://rcl-lab.github.io/Qutibench_Web/about/" />
<meta property="og:site_name" content="QuTiBench" />
<script type="application/ld+json">
{"@type":"WebSite","url":"https://rcl-lab.github.io/Qutibench_Web/about/","name":"QuTiBench","headline":"About This Work","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->

<link href="https://unpkg.com/@primer/css/dist/primer.css" rel="stylesheet" />
<link rel="stylesheet" href="//use.fontawesome.com/releases/v5.0.7/css/all.css"><link type="application/atom+xml" rel="alternate" href="https://rcl-lab.github.io/Qutibench_Web/feed.xml" title="QuTiBench" />

<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title") && (el.className != "emoji")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head><body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/Qutibench_Web/">QuTiBench</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/Qutibench_Web/about/">About This Work</a><a class="page-link" href="/Qutibench_Web/search/">Search</a><a class="page-link" href="/Qutibench_Web/categories/">Tags</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post">

  <header class="post-header">
    <h1 class="post-title">About This Work</h1>
  </header>

  <div class="post-content">
    <p><img src="/Qutibench_Web/images/QuTiBench_Logo.png" alt="logo" /></p>

<h1 id="qutibench">QuTiBench</h1>
<p>Neural Networks have become one of the most successful universal machine learning algorithms. 
They play a key role in enabling machine vision and speech recognition, and are increasingly 
adopted in other application domains. 
While the underlying computation is structurally simple, their computational complexity is enormous 
and comes along with equally challenging memory requirements both in regards to capacity and access bandwidth. 
This limits deployment in particular within energy constrained, embedded environments.<br />
In order to address these implementation challenges, a broad spectrum of new customized and heterogeneous 
hardware architectures have emerged, sometime referred to as deep learning processing units, 
often accompanied with co-designed algorithms to extract maximum benefit out of the hardware. 
Furthermore, numerous optimization techniques are being explored to reduce 
compute and memory requirements while maintaining accuracy.
This results in an abundance of algorithmic and architectural choices, some of which fit specific use cases 
better than others.</p>

<p>For system level designers, there is currently no good way to compare the variety of hardware, algorithm and 
optimization options. While there are many benchmarking efforts in this field, they cover only subsections of 
the embedded design space.  None of the existing benchmarks support essential algorithmic optimizations such as 
quantization, an important technique to stay on chip, or specialized heterogeneous hardware architectures. 
We propose a novel benchmark suite, named QuTiBench, that addresses this need.<br />
QuTiBench is a novel multi-tiered benchmarking methodology that supports algorithmic optimizations such as 
quantization and helps system developers understand the benefits and limitations of these novel compute architectures 
in regards to specific neural networks and will help drive future innovation.<br />
We invite the community to contribute to QuTiBench in order to be able to support the full spectrum of choices 
in implementing machine learning systems.</p>

<h1 id="contributing">Contributing</h1>
<p>See the <a href="https://rcl-lab.github.io/Qutibench_Web/contributing/meta/2020/04/09/Contributing_Measurements.html">website</a> for instructions on contributing.</p>

<h1 id="publications">Publications</h1>
<p>Blott, Michaela, et al. “QuTiBench: Benchmarking neural networks on heterogeneous hardware.” ACM Journal on Emerging Technologies in Computing Systems (JETC) 15.4 (2019): 1-38. <a href="https://arxiv.org/pdf/1909.05009.pdf">https://arxiv.org/pdf/1909.05009.pdf </a></p>

<p>Michaela Blott, Johannes Kath, Lisa Halder, Yaman Umuroglu, Nicholas Fraser, Giulio Gambardella, Miriam Leeser, and Linda Doyle. 2020. “Evaluation of Optimized CNNs on FPGA and non-FPGA based Accelerators using a Novel Benchmarking Approach.” In The 2020 ACM/SIGDA International Symposium on Field-Programmable Gate Arrays (FPGA ’20). Association for Computing Machinery, New York, NY, USA, 317. <a href="https://dl.acm.org/doi/10.1145/3373087.3375348">https://dl.acm.org/doi/10.1145/3373087.3375348 </a>.
<br />
Poster available <a href="https://github.com/michaelablott/QuTiBench/blob/master/Publications/FPGA2020_EvalCNNs_Poster.pdf">here</a></p>

<h1 id="about-us">About us</h1>

<h3 id="michaela-blott">Michaela Blott</h3>
<p><img align="left" src="../images/michaela_blott.png" alt="drawing" style="width:200px;height:200px;padding-right: 15px;" />
Michaela Blott is a Distinguished Engineer at Xilinx Research in Dublin, Ireland, where she heads a team of international scientists driving exciting research to define new application domains for Xilinx devices, such as machine learning, in both embedded and hyperscale deployments. She earned her Master’s degree from the University of Kaiserslautern in Germany and brings over 25 years of computer architecture, FPGA and board design, in research institutions (ETH Zurich and Bell Labs) and development organizations. She is heavily involved with the international research community serving as the technical co-chair of FPL’2018, workshop organizer (H2RC), industry advisor on numerous EU projects, and member of numerous technical program committees (FPL, ISFPGA, DATE, etc.).
<br />
Contact: mblott@xilinx.com</p>

<h3 id="miriam-leeser">Miriam Leeser</h3>
<p><img align="left" src="../images/miriam_leeser.png" alt="drawing" style="width:200px;height:250px;padding-right: 15px;" />
Miriam Leeser is Professor of Electrical and Computer Engineering at Northeastern University.  Her research interests are in hardware accelerators, including FPGAs and GPUs, as well as  floating point implementations, unsupervised learning, medical imaging, privacy preserving data processing and wireless networking and security.  She received her BS degree in Electrical Engineering from Cornell University, and Diploma and Ph.D. Degrees in Computer Science from Cambridge University in England.  She has been a faculty member at Northeastern since 1996, where she is head of the Reconfigurable and GPU Computing Laboratory and a member of the Computer Engineering group.  She is a senior member of ACM, IEEE and SWE. Throughout her career she has been funded by both government agencies and companies, including DARPA, NSF, Google, MathWorks and Microsoft. She received the prestigious Fulbright Scholar Award in 2018.
<br />
Contact: <a href="https://coe.northeastern.edu/Research/rcl/members/MEL/index.html">mel@coe.neu.edu</a></p>

<h3 id="linda-doyle">Linda Doyle</h3>

<h3 id="johannes-kath">Johannes Kath</h3>

<h3 id="zachary-neveu">Zachary Neveu</h3>
<p><img align="left" src="../images/zach_neveu.jpg" alt="drawing" style="width:200px;height:250px;padding-right: 15px;" /> 
Zachary Neveu was an undergraduate student at Northeastern University and now works at <a href="https://modulate.ai">Modulate.ai</a>.
<br />
Contact: zachary.neveu@gmail.com
 <br />
 <br />
 <br />
 <br />
 <br />
 <br /></p>

<h3 id="alina-vasilciuc">Alina Vasilciuc</h3>
<p><img align="left" src="../images/alina_vasilciuc.png" alt="drawing" style="width:200px;height:193px;padding-right: 15px;" /> 
Alina Vasilciuc is an undergraduate student at Nova University of Lisbon, currently working on her Master’s degree in collaboration with Xilinx Research, where she is currently doing an internship.
<br />
Contact: alina.vasilciuc@hotmail.com</p>

  </div>

</article>

      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/Qutibench_Web/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/Qutibench_Web/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/Qutibench_Web/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p></p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li><a rel="me" href="https://github.com/RCL-Lab" title="RCL-Lab"><svg class="svg-icon grey"><use xlink:href="/Qutibench_Web/assets/minima-social-icons.svg#github"></use></svg></a></li></ul>
</div>

  </div>

</footer>
</body>

</html>
