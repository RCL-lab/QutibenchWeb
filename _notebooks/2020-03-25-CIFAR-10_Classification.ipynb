{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# CIFAR-10 Classification\n",
    "> Performance analysis for CIFAR-10 Classification on all hardware platforms\n",
    "\n",
    "- toc: true \n",
    "- badges: true\n",
    "- comments: true\n",
    "- categories: [CIFAR-10,Rooflines,Performance Prediction]\n",
    "- image: images/cifar_logo.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import altair as alt\n",
    "\n",
    "W = 600\n",
    "H = 480\n",
    "\n",
    "csv_path = \"./data/cleaned_csv/backup.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Theretical Analysis of CIFAR-10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Rooflines for All Hardware Platforms and CNNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Combining application requirements with hardware platform characteristics can be leveraged for performance predictions using UCB’s roofline models. Using assumptions for where weights, activation tensors, and state of a neural network are stored, combined with the size of the datatypes used, allow us to derive the arithmetic intensity of a neural network during inference. Combined with the roofline for a given hardware platform, we can provide insight as to whether a neural network will be memory or compute bound and guidance for what is theoretically possible in regards to its throughput."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div id=\"altair-viz-0af5edff285245008855ae3601a6d350\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  (function(spec, embedOpt){\n",
       "    const outputDiv = document.getElementById(\"altair-viz-0af5edff285245008855ae3601a6d350\");\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.0.2?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function loadScript(lib) {\n",
       "      return new Promise(function(resolve, reject) {\n",
       "        var s = document.createElement('script');\n",
       "        s.src = paths[lib];\n",
       "        s.async = true;\n",
       "        s.onload = () => resolve(paths[lib]);\n",
       "        s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "        document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "      });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else if (typeof vegaEmbed === \"function\") {\n",
       "      displayChart(vegaEmbed);\n",
       "    } else {\n",
       "      loadScript(\"vega\")\n",
       "        .then(() => loadScript(\"vega-lite\"))\n",
       "        .then(() => loadScript(\"vega-embed\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"layer\": [{\"layer\": [{\"data\": {\"name\": \"data-dc7dec0718c32350856b8048bd9f9e72\"}, \"mark\": {\"type\": \"line\", \"clip\": true}, \"encoding\": {\"color\": {\"condition\": {\"type\": \"nominal\", \"field\": \"Name\", \"selection\": \"CIFAR-10  CNV  \"}, \"value\": \"lightgray\"}, \"x\": {\"type\": \"quantitative\", \"field\": \"arith_intens\", \"scale\": {\"domain\": [0.1, 160000], \"type\": \"log\"}, \"title\": \"ARITHMETIC INTENSITY (OPS/BYTE)\"}, \"y\": {\"type\": \"quantitative\", \"field\": \"performance\", \"scale\": {\"domain\": [0.2, 40], \"type\": \"log\"}, \"title\": \"PERFORMANCE (TOPS/S)\"}}, \"height\": 500, \"selection\": {\"CIFAR-10  CNV  \": {\"type\": \"single\", \"fields\": [\"Hide\"], \"bind\": {\"input\": \"checkbox\"}}}, \"title\": \"Comparing Hardware Platforms Rooflines and Neural Networks Arithmetic Intensity\", \"width\": 700}, {\"data\": {\"name\": \"data-0dbd2e620362f0c9cc95f43709e53a26\"}, \"mark\": {\"type\": \"line\", \"clip\": true}, \"encoding\": {\"color\": {\"condition\": {\"type\": \"nominal\", \"field\": \"Name\", \"selection\": \"FPGAs  Ultra96  DPU  ZCU  \"}, \"value\": \"lightgray\"}, \"x\": {\"type\": \"quantitative\", \"field\": \"arith_intens\", \"scale\": {\"domain\": [0.1, 160000], \"type\": \"log\"}, \"title\": \"ARITHMETIC INTENSITY (OPS/BYTE)\"}, \"y\": {\"type\": \"quantitative\", \"field\": \"performance\", \"scale\": {\"domain\": [0.2, 40], \"type\": \"log\"}, \"title\": \"PERFORMANCE (TOPS/S)\"}}, \"height\": 500, \"selection\": {\"FPGAs  Ultra96  DPU  ZCU  \": {\"type\": \"single\", \"fields\": [\"Hide\"], \"bind\": {\"input\": \"checkbox\"}}}, \"title\": \"Comparing Hardware Platforms Rooflines and Neural Networks Arithmetic Intensity\", \"width\": 700}, {\"data\": {\"name\": \"data-ab281f04283375347fb9d70efb25c187\"}, \"mark\": {\"type\": \"line\", \"clip\": true}, \"encoding\": {\"color\": {\"condition\": {\"type\": \"nominal\", \"field\": \"Name\", \"selection\": \"INVIDIA  TX2  maxn, maxp, maxq  \"}, \"value\": \"lightgray\"}, \"x\": {\"type\": \"quantitative\", \"field\": \"arith_intens\", \"scale\": {\"domain\": [0.1, 160000], \"type\": \"log\"}, \"title\": \"ARITHMETIC INTENSITY (OPS/BYTE)\"}, \"y\": {\"type\": \"quantitative\", \"field\": \"performance\", \"scale\": {\"domain\": [0.2, 40], \"type\": \"log\"}, \"title\": \"PERFORMANCE (TOPS/S)\"}}, \"height\": 500, \"selection\": {\"INVIDIA  TX2  maxn, maxp, maxq  \": {\"type\": \"single\", \"fields\": [\"Hide\"], \"bind\": {\"input\": \"checkbox\"}}}, \"title\": \"Comparing Hardware Platforms Rooflines and Neural Networks Arithmetic Intensity\", \"width\": 700}, {\"data\": {\"name\": \"data-200f229595649ff40f8895e65bc8e94a\"}, \"mark\": {\"type\": \"line\", \"clip\": true}, \"encoding\": {\"color\": {\"condition\": {\"type\": \"nominal\", \"field\": \"Name\", \"selection\": \"GOOGLE  TPU, fast, slow  \"}, \"value\": \"lightgray\"}, \"x\": {\"type\": \"quantitative\", \"field\": \"arith_intens\", \"scale\": {\"domain\": [0.1, 160000], \"type\": \"log\"}, \"title\": \"ARITHMETIC INTENSITY (OPS/BYTE)\"}, \"y\": {\"type\": \"quantitative\", \"field\": \"performance\", \"scale\": {\"domain\": [0.2, 40], \"type\": \"log\"}, \"title\": \"PERFORMANCE (TOPS/S)\"}}, \"height\": 500, \"selection\": {\"GOOGLE  TPU, fast, slow  \": {\"type\": \"single\", \"fields\": [\"Hide\"], \"bind\": {\"input\": \"checkbox\"}}}, \"title\": \"Comparing Hardware Platforms Rooflines and Neural Networks Arithmetic Intensity\", \"width\": 700}, {\"data\": {\"name\": \"data-6db333fb66ba5d428ce716da139cf6e8\"}, \"mark\": {\"type\": \"line\", \"clip\": true}, \"encoding\": {\"color\": {\"condition\": {\"type\": \"nominal\", \"field\": \"Name\", \"selection\": \"INTEL  NCS  \"}, \"value\": \"lightgray\"}, \"x\": {\"type\": \"quantitative\", \"field\": \"arith_intens\", \"scale\": {\"domain\": [0.1, 160000], \"type\": \"log\"}, \"title\": \"ARITHMETIC INTENSITY (OPS/BYTE)\"}, \"y\": {\"type\": \"quantitative\", \"field\": \"performance\", \"scale\": {\"domain\": [0.2, 40], \"type\": \"log\"}, \"title\": \"PERFORMANCE (TOPS/S)\"}}, \"height\": 500, \"selection\": {\"INTEL  NCS  \": {\"type\": \"single\", \"fields\": [\"Hide\"], \"bind\": {\"input\": \"checkbox\"}}}, \"title\": \"Comparing Hardware Platforms Rooflines and Neural Networks Arithmetic Intensity\", \"width\": 700}]}, {\"mark\": {\"type\": \"point\", \"clip\": true}, \"encoding\": {\"opacity\": {\"value\": 0}, \"x\": {\"type\": \"quantitative\", \"field\": \"arith_intens\"}, \"y\": {\"type\": \"quantitative\", \"field\": \"performance\"}}, \"selection\": {\"selector002\": {\"type\": \"single\", \"nearest\": true, \"on\": \"mouseover\", \"fields\": [\"arith_intens\"]}}}, {\"mark\": {\"type\": \"text\", \"align\": \"left\", \"clip\": true, \"dx\": 3, \"dy\": -3}, \"encoding\": {\"color\": {\"type\": \"nominal\", \"field\": \"Name\", \"legend\": {\"columns\": 2}}, \"text\": {\"condition\": {\"type\": \"nominal\", \"field\": \"Name\", \"selection\": \"selector002\"}, \"value\": \" \"}, \"x\": {\"type\": \"quantitative\", \"field\": \"arith_intens\"}, \"y\": {\"type\": \"quantitative\", \"field\": \"performance\"}}, \"selection\": {\"selector001\": {\"type\": \"interval\", \"bind\": \"scales\", \"encodings\": [\"x\", \"y\"]}}}], \"data\": {\"name\": \"data-57461a4ee55a7f4d76bd730db00783a8\"}, \"height\": 500, \"width\": 700, \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.0.2.json\", \"datasets\": {\"data-57461a4ee55a7f4d76bd730db00783a8\": [{\"Name\": \"Ultra96 DPU INT8\", \"arith_intens\": 12.1, \"performance\": 0.051546}, {\"Name\": \"Ultra96 DPU INT8\", \"arith_intens\": 226.1, \"performance\": 0.96}, {\"Name\": \"Ultra96 DPU INT8\", \"arith_intens\": 160000.0, \"performance\": 0.96}, {\"Name\": \"ZCU104 INT8\", \"arith_intens\": 3.1, \"performance\": 0.05952}, {\"Name\": \"ZCU104 INT8\", \"arith_intens\": 240.1, \"performance\": 4.6}, {\"Name\": \"ZCU104 INT8\", \"arith_intens\": 160000.0, \"performance\": 4.6}, {\"Name\": \"ZCU102 INT8\", \"arith_intens\": 3.1, \"performance\": 0.05952}, {\"Name\": \"ZCU102 INT8\", \"arith_intens\": 350.1, \"performance\": 6.71}, {\"Name\": \"ZCU102 INT8\", \"arith_intens\": 160000.0, \"performance\": 6.71}, {\"Name\": \"ZCU104 FINN INT2\", \"arith_intens\": 3.1, \"performance\": 0.05952}, {\"Name\": \"ZCU104 FINN INT2\", \"arith_intens\": 1599.1, \"performance\": 30.7}, {\"Name\": \"ZCU104 FINN INT2\", \"arith_intens\": 160000.0, \"performance\": 30.7}, {\"Name\": \"ZCU104 FINN INT4\", \"arith_intens\": 3.1, \"performance\": 0.05952}, {\"Name\": \"ZCU104 FINN INT4\", \"arith_intens\": 459.1, \"performance\": 8.8}, {\"Name\": \"ZCU104 FINN INT4\", \"arith_intens\": 160000.0, \"performance\": 8.8}, {\"Name\": \"ZCU104 FINN INT8\", \"arith_intens\": 3.1, \"performance\": 0.05952}, {\"Name\": \"ZCU104 FINN INT8\", \"arith_intens\": 183.1, \"performance\": 3.5}, {\"Name\": \"ZCU104 FINN INT8\", \"arith_intens\": 160000.0, \"performance\": 3.5}, {\"Name\": \"ZCU104 FINN FP16\", \"arith_intens\": 3.1, \"performance\": 0.05952}, {\"Name\": \"ZCU104 FINN FP16\", \"arith_intens\": 91.1, \"performance\": 1.73}, {\"Name\": \"ZCU104 FINN FP16\", \"arith_intens\": 160000.0, \"performance\": 1.73}, {\"Name\": \"ZCU104 BISMO INT2\", \"arith_intens\": 3.1, \"performance\": 0.05952}, {\"Name\": \"ZCU104 BISMO INT2\", \"arith_intens\": 128.1, \"performance\": 2.45}, {\"Name\": \"ZCU104 BISMO INT2\", \"arith_intens\": 160000.0, \"performance\": 2.45}, {\"Name\": \"ZCU104 BISMO INT4\", \"arith_intens\": 3.1, \"performance\": 0.05952}, {\"Name\": \"ZCU104 BISMO INT4\", \"arith_intens\": 32.1, \"performance\": 0.61}, {\"Name\": \"ZCU104 BISMO INT4\", \"arith_intens\": 160000.0, \"performance\": 0.61}, {\"Name\": \"TX2 maxn FP16\", \"arith_intens\": 1.1, \"performance\": 0.06567}, {\"Name\": \"TX2 maxn FP16\", \"arith_intens\": 23.1, \"performance\": 1.33}, {\"Name\": \"TX2 maxn FP16\", \"arith_intens\": 160000.0, \"performance\": 1.33}, {\"Name\": \"TX2 maxn FP32\", \"arith_intens\": 1.1, \"performance\": 0.06567}, {\"Name\": \"TX2 maxn FP32\", \"arith_intens\": 12.1, \"performance\": 0.67}, {\"Name\": \"TX2 maxn FP32\", \"arith_intens\": 160000.0, \"performance\": 0.67}, {\"Name\": \"TX2 maxp FP16\", \"arith_intens\": 1.1, \"performance\": 0.06567}, {\"Name\": \"TX2 maxp FP16\", \"arith_intens\": 20.1, \"performance\": 1.15}, {\"Name\": \"TX2 maxp FP16\", \"arith_intens\": 160000.0, \"performance\": 1.15}, {\"Name\": \"TX2 maxp FP32\", \"arith_intens\": 1.1, \"performance\": 0.06567}, {\"Name\": \"TX2 maxp FP32\", \"arith_intens\": 10.1, \"performance\": 0.57}, {\"Name\": \"TX2 maxp FP32\", \"arith_intens\": 160000.0, \"performance\": 0.57}, {\"Name\": \"TX2 maxq FP16\", \"arith_intens\": 1.1, \"performance\": 0.06567}, {\"Name\": \"TX2 maxq FP16\", \"arith_intens\": 15.1, \"performance\": 0.87}, {\"Name\": \"TX2 maxq FP16\", \"arith_intens\": 160000.0, \"performance\": 0.87}, {\"Name\": \"TX2 maxq FP32\", \"arith_intens\": 1.1, \"performance\": 0.06567}, {\"Name\": \"TX2 maxq FP32\", \"arith_intens\": 8.1, \"performance\": 0.44}, {\"Name\": \"TX2 maxq FP32\", \"arith_intens\": 160000.0, \"performance\": 0.44}, {\"Name\": \"TPU fast INT8\", \"arith_intens\": 2.1, \"performance\": 0.05376}, {\"Name\": \"TPU fast INT8\", \"arith_intens\": 157.1, \"performance\": 4.0}, {\"Name\": \"TPU fast INT8\", \"arith_intens\": 160000.0, \"performance\": 4.0}, {\"Name\": \"TPU slow INT8\", \"arith_intens\": 2.1, \"performance\": 0.05376}, {\"Name\": \"TPU slow INT8\", \"arith_intens\": 79.1, \"performance\": 2.0}, {\"Name\": \"TPU slow INT8\", \"arith_intens\": 160000.0, \"performance\": 2.0}, {\"Name\": \"NCS INT8\", \"arith_intens\": 4.1, \"performance\": 0.05248}, {\"Name\": \"NCS INT8\", \"arith_intens\": 79.1, \"performance\": 1.0}, {\"Name\": \"NCS INT8\", \"arith_intens\": 160000.0, \"performance\": 1.0}, {\"Name\": \"NCS FP16\", \"arith_intens\": 4.1, \"performance\": 0.05248}, {\"Name\": \"NCS FP16\", \"arith_intens\": 39.1, \"performance\": 0.5}, {\"Name\": \"NCS FP16\", \"arith_intens\": 160000.0, \"performance\": 0.5}, {\"Name\": \"MobileNet V1\", \"arith_intens\": 23878.0, \"performance\": 100.0}, {\"Name\": \"AlexNet\", \"arith_intens\": 2995.0, \"performance\": 100.0}, {\"Name\": \"GoogLeNet V1\", \"arith_intens\": 29988.0, \"performance\": 100.0}, {\"Name\": \"ResNet-18\", \"arith_intens\": 39950.0, \"performance\": 100.0}, {\"Name\": \"ResNet-34\", \"arith_intens\": 43169.0, \"performance\": 100.0}, {\"Name\": \"VGG16_BN\", \"arith_intens\": 7183.0, \"performance\": 100.0}, {\"Name\": \"ResNet-101\", \"arith_intens\": 22671.0, \"performance\": 100.0}, {\"Name\": \"ResNet-34-SSD\", \"arith_intens\": 51070.0, \"performance\": 100.0}, {\"Name\": \"ResNet-50\", \"arith_intens\": 41475.0, \"performance\": 100.0}, {\"Name\": \"ResNet-152\", \"arith_intens\": 24587.0, \"performance\": 100.0}, {\"Name\": \"MaskRCNN\", \"arith_intens\": 145921.0, \"performance\": 100.0}, {\"Name\": \"GNMT\", \"arith_intens\": 6086.0, \"performance\": 100.0}, {\"Name\": \"ResNet-50_\", \"arith_intens\": 82560.0, \"performance\": 100.0}, {\"Name\": \"MaskRCNN\", \"arith_intens\": 145921.0, \"performance\": 100.0}, {\"Name\": \"MobileNet V2\", \"arith_intens\": 12464.0, \"performance\": 100.0}, {\"Name\": \"GNMT\", \"arith_intens\": 9009.0, \"performance\": 100.0}, {\"Name\": \"MLP\", \"arith_intens\": 2.0, \"performance\": 100.0}, {\"Name\": \"CNV\", \"arith_intens\": 76.0, \"performance\": 100.0}, {\"Name\": \"CNV-50%\", \"arith_intens\": 77.0, \"performance\": 100.0}, {\"Name\": \"CNV-25%\", \"arith_intens\": 78.0, \"performance\": 100.0}, {\"Name\": \"CNV-12.5%\", \"arith_intens\": 83.0, \"performance\": 100.0}, {\"Name\": \"MLP-50%\", \"arith_intens\": 2.0, \"performance\": 100.0}, {\"Name\": \"MLP-25%\", \"arith_intens\": 2.0, \"performance\": 100.0}, {\"Name\": \"MobileNet V1\", \"arith_intens\": 23878.0, \"performance\": 25.0}, {\"Name\": \"AlexNet\", \"arith_intens\": 2995.0, \"performance\": 25.0}, {\"Name\": \"GoogLeNet V1\", \"arith_intens\": 29988.0, \"performance\": 25.0}, {\"Name\": \"ResNet-18\", \"arith_intens\": 39950.0, \"performance\": 25.0}, {\"Name\": \"ResNet-34\", \"arith_intens\": 43169.0, \"performance\": 25.0}, {\"Name\": \"VGG16_BN\", \"arith_intens\": 7183.0, \"performance\": 25.0}, {\"Name\": \"ResNet-101\", \"arith_intens\": 22671.0, \"performance\": 25.0}, {\"Name\": \"ResNet-34-SSD\", \"arith_intens\": 51070.0, \"performance\": 25.0}, {\"Name\": \"ResNet-50\", \"arith_intens\": 41475.0, \"performance\": 25.0}, {\"Name\": \"ResNet-152\", \"arith_intens\": 24587.0, \"performance\": 25.0}, {\"Name\": \"MaskRCNN\", \"arith_intens\": 145921.0, \"performance\": 25.0}, {\"Name\": \"GNMT\", \"arith_intens\": 6086.0, \"performance\": 25.0}, {\"Name\": \"ResNet-50_\", \"arith_intens\": 82560.0, \"performance\": 25.0}, {\"Name\": \"MaskRCNN\", \"arith_intens\": 145921.0, \"performance\": 25.0}, {\"Name\": \"MobileNet V2\", \"arith_intens\": 12464.0, \"performance\": 25.0}, {\"Name\": \"GNMT\", \"arith_intens\": 9009.0, \"performance\": 25.0}, {\"Name\": \"MLP\", \"arith_intens\": 2.0, \"performance\": 25.0}, {\"Name\": \"CNV\", \"arith_intens\": 76.0, \"performance\": 25.0}, {\"Name\": \"CNV-50%\", \"arith_intens\": 77.0, \"performance\": 25.0}, {\"Name\": \"CNV-25%\", \"arith_intens\": 78.0, \"performance\": 25.0}, {\"Name\": \"CNV-12.5%\", \"arith_intens\": 83.0, \"performance\": 25.0}, {\"Name\": \"MLP-50%\", \"arith_intens\": 2.0, \"performance\": 25.0}, {\"Name\": \"MLP-25%\", \"arith_intens\": 2.0, \"performance\": 25.0}, {\"Name\": \"MobileNet V1\", \"arith_intens\": 23878.0, \"performance\": 75.0}, {\"Name\": \"AlexNet\", \"arith_intens\": 2995.0, \"performance\": 75.0}, {\"Name\": \"GoogLeNet V1\", \"arith_intens\": 29988.0, \"performance\": 75.0}, {\"Name\": \"ResNet-18\", \"arith_intens\": 39950.0, \"performance\": 75.0}, {\"Name\": \"ResNet-34\", \"arith_intens\": 43169.0, \"performance\": 75.0}, {\"Name\": \"VGG16_BN\", \"arith_intens\": 7183.0, \"performance\": 75.0}, {\"Name\": \"ResNet-101\", \"arith_intens\": 22671.0, \"performance\": 75.0}, {\"Name\": \"ResNet-34-SSD\", \"arith_intens\": 51070.0, \"performance\": 75.0}, {\"Name\": \"ResNet-50\", \"arith_intens\": 41475.0, \"performance\": 75.0}, {\"Name\": \"ResNet-152\", \"arith_intens\": 24587.0, \"performance\": 75.0}, {\"Name\": \"MaskRCNN\", \"arith_intens\": 145921.0, \"performance\": 75.0}, {\"Name\": \"GNMT\", \"arith_intens\": 6086.0, \"performance\": 75.0}, {\"Name\": \"ResNet-50_\", \"arith_intens\": 82560.0, \"performance\": 75.0}, {\"Name\": \"MaskRCNN\", \"arith_intens\": 145921.0, \"performance\": 75.0}, {\"Name\": \"MobileNet V2\", \"arith_intens\": 12464.0, \"performance\": 75.0}, {\"Name\": \"GNMT\", \"arith_intens\": 9009.0, \"performance\": 75.0}, {\"Name\": \"MLP\", \"arith_intens\": 2.0, \"performance\": 75.0}, {\"Name\": \"CNV\", \"arith_intens\": 76.0, \"performance\": 75.0}, {\"Name\": \"CNV-50%\", \"arith_intens\": 77.0, \"performance\": 75.0}, {\"Name\": \"CNV-25%\", \"arith_intens\": 78.0, \"performance\": 75.0}, {\"Name\": \"CNV-12.5%\", \"arith_intens\": 83.0, \"performance\": 75.0}, {\"Name\": \"MLP-50%\", \"arith_intens\": 2.0, \"performance\": 75.0}, {\"Name\": \"MLP-25%\", \"arith_intens\": 2.0, \"performance\": 75.0}, {\"Name\": \"MobileNet V1\", \"arith_intens\": 23878.0, \"performance\": 0.1}, {\"Name\": \"AlexNet\", \"arith_intens\": 2995.0, \"performance\": 0.1}, {\"Name\": \"GoogLeNet V1\", \"arith_intens\": 29988.0, \"performance\": 0.1}, {\"Name\": \"ResNet-18\", \"arith_intens\": 39950.0, \"performance\": 0.1}, {\"Name\": \"ResNet-34\", \"arith_intens\": 43169.0, \"performance\": 0.1}, {\"Name\": \"VGG16_BN\", \"arith_intens\": 7183.0, \"performance\": 0.1}, {\"Name\": \"ResNet-101\", \"arith_intens\": 22671.0, \"performance\": 0.1}, {\"Name\": \"ResNet-34-SSD\", \"arith_intens\": 51070.0, \"performance\": 0.1}, {\"Name\": \"ResNet-50\", \"arith_intens\": 41475.0, \"performance\": 0.1}, {\"Name\": \"ResNet-152\", \"arith_intens\": 24587.0, \"performance\": 0.1}, {\"Name\": \"MaskRCNN\", \"arith_intens\": 145921.0, \"performance\": 0.1}, {\"Name\": \"GNMT\", \"arith_intens\": 6086.0, \"performance\": 0.1}, {\"Name\": \"ResNet-50_\", \"arith_intens\": 82560.0, \"performance\": 0.1}, {\"Name\": \"MaskRCNN\", \"arith_intens\": 145921.0, \"performance\": 0.1}, {\"Name\": \"MobileNet V2\", \"arith_intens\": 12464.0, \"performance\": 0.1}, {\"Name\": \"GNMT\", \"arith_intens\": 9009.0, \"performance\": 0.1}, {\"Name\": \"MLP\", \"arith_intens\": 2.0, \"performance\": 0.1}, {\"Name\": \"CNV\", \"arith_intens\": 76.0, \"performance\": 0.1}, {\"Name\": \"CNV-50%\", \"arith_intens\": 77.0, \"performance\": 0.1}, {\"Name\": \"CNV-25%\", \"arith_intens\": 78.0, \"performance\": 0.1}, {\"Name\": \"CNV-12.5%\", \"arith_intens\": 83.0, \"performance\": 0.1}, {\"Name\": \"MLP-50%\", \"arith_intens\": 2.0, \"performance\": 0.1}, {\"Name\": \"MLP-25%\", \"arith_intens\": 2.0, \"performance\": 0.1}], \"data-dc7dec0718c32350856b8048bd9f9e72\": [{\"Name\": \"CNV\", \"arith_intens\": 76.0, \"performance\": 100.0}, {\"Name\": \"CNV-50%\", \"arith_intens\": 77.0, \"performance\": 100.0}, {\"Name\": \"CNV-25%\", \"arith_intens\": 78.0, \"performance\": 100.0}, {\"Name\": \"CNV-12.5%\", \"arith_intens\": 83.0, \"performance\": 100.0}, {\"Name\": \"CNV\", \"arith_intens\": 76.0, \"performance\": 25.0}, {\"Name\": \"CNV-50%\", \"arith_intens\": 77.0, \"performance\": 25.0}, {\"Name\": \"CNV-25%\", \"arith_intens\": 78.0, \"performance\": 25.0}, {\"Name\": \"CNV-12.5%\", \"arith_intens\": 83.0, \"performance\": 25.0}, {\"Name\": \"CNV\", \"arith_intens\": 76.0, \"performance\": 75.0}, {\"Name\": \"CNV-50%\", \"arith_intens\": 77.0, \"performance\": 75.0}, {\"Name\": \"CNV-25%\", \"arith_intens\": 78.0, \"performance\": 75.0}, {\"Name\": \"CNV-12.5%\", \"arith_intens\": 83.0, \"performance\": 75.0}, {\"Name\": \"CNV\", \"arith_intens\": 76.0, \"performance\": 0.1}, {\"Name\": \"CNV-50%\", \"arith_intens\": 77.0, \"performance\": 0.1}, {\"Name\": \"CNV-25%\", \"arith_intens\": 78.0, \"performance\": 0.1}, {\"Name\": \"CNV-12.5%\", \"arith_intens\": 83.0, \"performance\": 0.1}], \"data-0dbd2e620362f0c9cc95f43709e53a26\": [{\"Name\": \"Ultra96 DPU INT8\", \"arith_intens\": 12.1, \"performance\": 0.051546}, {\"Name\": \"Ultra96 DPU INT8\", \"arith_intens\": 226.1, \"performance\": 0.96}, {\"Name\": \"Ultra96 DPU INT8\", \"arith_intens\": 160000.0, \"performance\": 0.96}, {\"Name\": \"ZCU104 INT8\", \"arith_intens\": 3.1, \"performance\": 0.05952}, {\"Name\": \"ZCU104 INT8\", \"arith_intens\": 240.1, \"performance\": 4.6}, {\"Name\": \"ZCU104 INT8\", \"arith_intens\": 160000.0, \"performance\": 4.6}, {\"Name\": \"ZCU102 INT8\", \"arith_intens\": 3.1, \"performance\": 0.05952}, {\"Name\": \"ZCU102 INT8\", \"arith_intens\": 350.1, \"performance\": 6.71}, {\"Name\": \"ZCU102 INT8\", \"arith_intens\": 160000.0, \"performance\": 6.71}, {\"Name\": \"ZCU104 FINN INT2\", \"arith_intens\": 3.1, \"performance\": 0.05952}, {\"Name\": \"ZCU104 FINN INT2\", \"arith_intens\": 1599.1, \"performance\": 30.7}, {\"Name\": \"ZCU104 FINN INT2\", \"arith_intens\": 160000.0, \"performance\": 30.7}, {\"Name\": \"ZCU104 FINN INT4\", \"arith_intens\": 3.1, \"performance\": 0.05952}, {\"Name\": \"ZCU104 FINN INT4\", \"arith_intens\": 459.1, \"performance\": 8.8}, {\"Name\": \"ZCU104 FINN INT4\", \"arith_intens\": 160000.0, \"performance\": 8.8}, {\"Name\": \"ZCU104 FINN INT8\", \"arith_intens\": 3.1, \"performance\": 0.05952}, {\"Name\": \"ZCU104 FINN INT8\", \"arith_intens\": 183.1, \"performance\": 3.5}, {\"Name\": \"ZCU104 FINN INT8\", \"arith_intens\": 160000.0, \"performance\": 3.5}, {\"Name\": \"ZCU104 FINN FP16\", \"arith_intens\": 3.1, \"performance\": 0.05952}, {\"Name\": \"ZCU104 FINN FP16\", \"arith_intens\": 91.1, \"performance\": 1.73}, {\"Name\": \"ZCU104 FINN FP16\", \"arith_intens\": 160000.0, \"performance\": 1.73}, {\"Name\": \"ZCU104 BISMO INT2\", \"arith_intens\": 3.1, \"performance\": 0.05952}, {\"Name\": \"ZCU104 BISMO INT2\", \"arith_intens\": 128.1, \"performance\": 2.45}, {\"Name\": \"ZCU104 BISMO INT2\", \"arith_intens\": 160000.0, \"performance\": 2.45}, {\"Name\": \"ZCU104 BISMO INT4\", \"arith_intens\": 3.1, \"performance\": 0.05952}, {\"Name\": \"ZCU104 BISMO INT4\", \"arith_intens\": 32.1, \"performance\": 0.61}, {\"Name\": \"ZCU104 BISMO INT4\", \"arith_intens\": 160000.0, \"performance\": 0.61}], \"data-ab281f04283375347fb9d70efb25c187\": [{\"Name\": \"TX2 maxn FP16\", \"arith_intens\": 1.1, \"performance\": 0.06567}, {\"Name\": \"TX2 maxn FP16\", \"arith_intens\": 23.1, \"performance\": 1.33}, {\"Name\": \"TX2 maxn FP16\", \"arith_intens\": 160000.0, \"performance\": 1.33}, {\"Name\": \"TX2 maxn FP32\", \"arith_intens\": 1.1, \"performance\": 0.06567}, {\"Name\": \"TX2 maxn FP32\", \"arith_intens\": 12.1, \"performance\": 0.67}, {\"Name\": \"TX2 maxn FP32\", \"arith_intens\": 160000.0, \"performance\": 0.67}, {\"Name\": \"TX2 maxp FP16\", \"arith_intens\": 1.1, \"performance\": 0.06567}, {\"Name\": \"TX2 maxp FP16\", \"arith_intens\": 20.1, \"performance\": 1.15}, {\"Name\": \"TX2 maxp FP16\", \"arith_intens\": 160000.0, \"performance\": 1.15}, {\"Name\": \"TX2 maxp FP32\", \"arith_intens\": 1.1, \"performance\": 0.06567}, {\"Name\": \"TX2 maxp FP32\", \"arith_intens\": 10.1, \"performance\": 0.57}, {\"Name\": \"TX2 maxp FP32\", \"arith_intens\": 160000.0, \"performance\": 0.57}, {\"Name\": \"TX2 maxq FP16\", \"arith_intens\": 1.1, \"performance\": 0.06567}, {\"Name\": \"TX2 maxq FP16\", \"arith_intens\": 15.1, \"performance\": 0.87}, {\"Name\": \"TX2 maxq FP16\", \"arith_intens\": 160000.0, \"performance\": 0.87}, {\"Name\": \"TX2 maxq FP32\", \"arith_intens\": 1.1, \"performance\": 0.06567}, {\"Name\": \"TX2 maxq FP32\", \"arith_intens\": 8.1, \"performance\": 0.44}, {\"Name\": \"TX2 maxq FP32\", \"arith_intens\": 160000.0, \"performance\": 0.44}], \"data-200f229595649ff40f8895e65bc8e94a\": [{\"Name\": \"TPU fast INT8\", \"arith_intens\": 2.1, \"performance\": 0.05376}, {\"Name\": \"TPU fast INT8\", \"arith_intens\": 157.1, \"performance\": 4.0}, {\"Name\": \"TPU fast INT8\", \"arith_intens\": 160000.0, \"performance\": 4.0}, {\"Name\": \"TPU slow INT8\", \"arith_intens\": 2.1, \"performance\": 0.05376}, {\"Name\": \"TPU slow INT8\", \"arith_intens\": 79.1, \"performance\": 2.0}, {\"Name\": \"TPU slow INT8\", \"arith_intens\": 160000.0, \"performance\": 2.0}], \"data-6db333fb66ba5d428ce716da139cf6e8\": [{\"Name\": \"NCS INT8\", \"arith_intens\": 4.1, \"performance\": 0.05248}, {\"Name\": \"NCS INT8\", \"arith_intens\": 79.1, \"performance\": 1.0}, {\"Name\": \"NCS INT8\", \"arith_intens\": 160000.0, \"performance\": 1.0}, {\"Name\": \"NCS FP16\", \"arith_intens\": 4.1, \"performance\": 0.05248}, {\"Name\": \"NCS FP16\", \"arith_intens\": 39.1, \"performance\": 0.5}, {\"Name\": \"NCS FP16\", \"arith_intens\": 160000.0, \"performance\": 0.5}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.LayerChart(...)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#hide_input\n",
    "\n",
    "#first process the following csv's to get clean ready-to-plot csv's\n",
    "%run scripts/script_load_save_data.py\n",
    "clean_csv_rooflines(path_topologies='c:/Users/alinav/Documents/GitHub/Qutibench_Web/_notebooks/data/topology_details.csv',\n",
    "                    path_hardware='c:/Users/alinav/Documents/GitHub/Qutibench_Web/_notebooks/data/peakPerfBandHardPlatf.csv')\n",
    "\n",
    "#Now get the cleaned csv, and plot it as a Roofline\n",
    "%run scripts/altair_plots.py\n",
    "rooflines(dataframe = pd.read_csv(\"data/cleaned_csv/rooflines_hardware_neural_networks.csv\"), \n",
    "          neural_network = 'cifar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Performance Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "The following heatmap shows the theoretical performance for the listed hardware platforms for CIFAR-10 classification. The metric used for the theoretical performance is input/second.\n",
    "We observe that prunning along with quantization outputs some of the best performance results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#hide_input\n",
    "%run scripts/altair_plots.py  #run the heatmaps script\n",
    "#load cifar10 dataset and plot it\n",
    "heatmap(pd.read_csv(\"data/cleaned_csv/performance_prediction_cifar10.csv\"), 'pink', 'Performance prediction for CIFAR-10')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Experimental Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Overview of All Measurements for CIFAR-10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this table, within the rows, we show the type of hardware platforms that we used for this task (for example FPGA or GPU) and then more specifically the exact name of the different hardware platforms. For each hardware platform, we list the sweep of specific deployment parameters (batch sizes, operating modes etc) that were used for the experimentation in separate columns. In the columns, we show CNN topologies. When a CNN topology was implemented on a given hardware platform, we show in the corresponding cell the precisions (quantization information) and the channel pruning scale. Otherwise, “na” indicates that the topology wasn’t executed on this specific hardware platform. Many combinations between topology and hardware platform are not supported by the vendors dedicated software environments. INTx depicts a fixed point integer representation with x bits. FPy represents a floating point representation with y bits, for example FP32 is singe precision floating point. Table follows below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#hide\n",
    "%run scripts/altair_plots.py   #get table with the experiments overview\n",
    "print(pd.read_csv('data/overview_experiments_cifar10.csv').to_markdown())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide_input\n",
    "%run scripts/altair_plots.py  #get table with the experiments overview\n",
    "tableOverviewExperiments(['data/overview_experiments_cifar10_.csv'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#hide\n",
    "#%writefile scripts/utils.py\n",
    "def norm_by_group(df, column, group_col):\n",
    "    \"\"\" Normalizes pandas series by group \"\"\"\n",
    "    df[\"norm-\"+column] = df.groupby(group_col)[column].apply(lambda x: (x / x.max()))\n",
    "    return df\n",
    "\n",
    "def select_color(sel, column):\n",
    "    \"\"\" Easy way to set colors based on selection for altair plots\n",
    "    \"\"\"\n",
    "    return alt.condition(sel, \n",
    "                      alt.Color(column),\n",
    "                      alt.value('lightgray'))\n",
    "\n",
    "def get_pareto_df(df, groupcol, xcol, ycol):\n",
    "    pareto_line_df = df.groupby(groupcol)[xcol].max().to_frame(\"x\")\n",
    "    pareto_line_df['y'] = df.groupby(groupcol)[ycol].agg(lambda x: x.value_counts().index[0])\n",
    "    pareto_line_df.sort_values('y', ascending=False, inplace=True)\n",
    "    pareto_line_df['x'] = pareto_line_df.x.cummax()\n",
    "    pareto_line_df.drop_duplicates('x', keep='first', inplace=True)\n",
    "    pareto_line_df['group'] = pareto_line_df.index\n",
    "    return pareto_line_df\n",
    "\n",
    "def label_point(x, y, val, ax, rot=0):\n",
    "    \"\"\" from https://stackoverflow.com/questions/46027653/adding-labels-in-x-y-scatter-plot-with-seaborn\"\"\"\n",
    "    a = pd.concat({'x': x, 'y': y, 'val': val}, axis=1)\n",
    "    for i, point in a.iterrows():\n",
    "        ax.text(point['x']+.02, point['y'], str(point['val']), rotation=rot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#hide\n",
    "master_df = pd.read_csv(csv_path)\n",
    "is_maxp = lambda row: row.HWType != \"GPU\" or row[\"Op mode\"].split(\",\")[0] == \"maxp\"\n",
    "maxp_df = master_df[master_df.apply(is_maxp, axis=1)]\n",
    "maxp_df[\"hw_quant_prun\"] = maxp_df.apply(lambda r: \"_\".join([r.HWType, r.Precision, r.PruningFactor]), axis=1)\n",
    "cnv_df = maxp_df[(maxp_df[\"NN_Topology\"] == \"CNV\") & maxp_df['lat-comp'].notna() & maxp_df[\"top1 [%]\"].notna()]\n",
    "cnv_df[\"hw_quant_prun\"] = cnv_df.apply(lambda r: \"_\".join([r.HWType, r.Precision, r.PruningFactor]), axis=1)\n",
    "cnv_df[\"PruningFactor\"] = cnv_df[\"PruningFactor\"].str.strip(\"%\").astype(float)\n",
    "norm_by_group(cnv_df, \"lat-comp\", \"NN_Topology\");\n",
    "cnv_df[\"quant_model\"] = cnv_df.Precision + '_' + cnv_df.HWType\n",
    "cnv_df.rename(columns={\"top1 [%]\": \"top1\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#hide\n",
    "figa_df = cnv_df[(cnv_df[\"HWType\"].isin([\"NCS\", \"ZCU104-Bismo\", \"U96-Quadcore A53\"]))]\n",
    "figb_df = cnv_df[(cnv_df[\"HWType\"].isin([\"GPU\", \"ZCU104-FINN\", \"U96-Quadcore A53\"]))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Line Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#hide_input\n",
    "fig25s = []\n",
    "fig25_dfs = [figa_df, figb_df]\n",
    "for df in fig25_dfs:\n",
    "    sel = alt.selection_multi(fields=[\"hw_quant_prun\"], bind=\"legend\")\n",
    "    fig25_dot = alt.Chart(df).mark_point().encode(\n",
    "        x='lat-comp',\n",
    "        y=alt.Y('fps-comp', scale=alt.Scale(type=\"log\")),\n",
    "        color=select_color(sel, 'hw_quant_prun:N'),\n",
    "        tooltip=['fps-comp', 'lat-comp', 'HWType', 'batch/thread/stream'],\n",
    "    )\n",
    "    fig25_line = alt.Chart(df).mark_line().encode(\n",
    "        x='lat-comp',\n",
    "        y='fps-comp',\n",
    "        color=select_color(sel, 'hw_quant_prun:N'),\n",
    "        tooltip=['fps-comp', 'lat-comp', 'HWType', 'batch/thread/stream'],\n",
    "    )\n",
    "\n",
    "    fig = (fig25_dot+fig25_line).properties(\n",
    "        title=\"Latency versus Performance for Pruned and Quantized CNV Variants\",\n",
    "        width=W/len(fig25_dfs),\n",
    "        height=H,\n",
    "    ).add_selection(sel).interactive()\n",
    "    \n",
    "    fig25s.append(fig)\n",
    "    \n",
    "alt.hconcat(*fig25s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Boxplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#hide_input\n",
    "box1 = alt.Chart(cnv_df).mark_boxplot().encode(\n",
    "    x='PruningFactor:O',\n",
    "    y=alt.Y(\"lat-comp\", scale=alt.Scale(type=\"log\")),\n",
    "    color='PruningFactor:O',\n",
    ").facet(column=\"quant_model\").properties(\n",
    "    title=\"Latency by Hardware/Framework and Pruning for CNV\"\n",
    ")\n",
    "box1.interactive()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#hide_input\n",
    "box1 = alt.Chart(cnv_df).mark_boxplot().encode(\n",
    "    x='PruningFactor:O',\n",
    "    y=alt.Y(\"fps-comp\", scale=alt.Scale(type=\"log\")),\n",
    "    color='PruningFactor:O',\n",
    ").facet(column=\"quant_model\").properties(\n",
    "    title=\"Throughput by Hardware/Framework and Pruning for CNV\",\n",
    ").interactive()\n",
    "box1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#hide_input\n",
    "box1 = alt.Chart(cnv_df).mark_boxplot().encode(\n",
    "    x='PruningFactor:O',\n",
    "    y=alt.Y(\"Full_Pwr_W\", scale=alt.Scale( type=\"log\")),\n",
    "    color=alt.Color('PruningFactor:O', legend=alt.Legend(columns=1, title = \"Pruning Factor\")),\n",
    ").facet(column=\"quant_model\").properties(\n",
    "    title=\"Power Consumption by Hardware/Framework and Pruning for CNV\",\n",
    ").interactive()\n",
    "box1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Pareto Graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following pareto graph presents the accuracy versus performance in fps for all the Hardware Platforms across different Pruning and Quantization configurations. This provides insights into accuracy-based comparisons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "#hide_input\n",
    "cnv_pareto = get_pareto_df(cnv_df, 'hw_quant_prun', 'fps-comp', 'top1')\n",
    "\n",
    "cnv_lines = alt.Chart(cnv_df).mark_line(point=True).encode(\n",
    "    x=\"fps-comp\",\n",
    "    y=alt.Y(\"top1:Q\", scale=alt.Scale(zero=False)),\n",
    "    color=alt.Color(\"hw_quant_prun\", legend=alt.Legend(columns=1, title = \"Hardware_Quantization_Pruning\")),\n",
    "    tooltip=[\"HWType\", \"Precision\", \"PruningFactor\", \"batch/thread/stream\", \"top1\", \"fps-comp\"],\n",
    ")\n",
    "cnv_pareto_plot = alt.Chart(cnv_pareto).mark_line().encode(\n",
    "    x=\"x\",\n",
    "    y=alt.Y(\"y\", scale=alt.Scale(zero=False)),\n",
    ")\n",
    "(cnv_lines+cnv_pareto_plot).interactive().properties(\n",
    "    width=W,\n",
    "    height=H,\n",
    "    title=\"cnv Cassification Design Space: Accuracy versus Performance\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#hide\n",
    "cnv_df.to_csv('data/cleaned_csv/experimental_data_cifar.csv', index = False)\n",
    "cnv_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
