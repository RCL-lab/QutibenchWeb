{
  
    
        "post0": {
            "title": "Overview of the Experiments",
            "content": "An overview of all experiments . toc:true - badges: true | comments: true | categories: [jupyter] | . Introduction . This page will present a quick overview of all experiments done. . Tables . These tables show.. Lorem ipsum.. . CIFAR10 Classification . Hardware Platform CNV . FPGA | ZCU102-DPU | na | . | ZCU104-DPU | na | . | Ultra96-DPU | na | . | ZCU104-FINN | [INT2,INT4]*[100%,50%,25%,12.5%] | . | ZCU104-BISMO | [INT2,INT4]*[100%,50%,25%,12.5%] | . GPU | TX2-maxn | [FP16,FP32]*[100%,50%,25%,12.5%] | . | TX2-maxp | [FP16,FP32]*[100%,50%,25%,12.5%] | . | TX2-maxq | [FP16,FP32]*[100%,50%,25%,12.5%] | . TPU | TPU-fast clk | na | . | TPU-slow clk | na | . VLIW | NCS | [FP16]*[100%,50%,25%,12.5%] | . CPU | U96-Quadcore A53 | [INT2,INT4]*[100%,50%,25%,12.5%] | . MNIST Classification . Hardware Platform MLP . FPGA | ZCU102-DPU | na | . | ZCU104-DPU | na | . | Ultra96-DPU | na | . | ZCU104-FINN | [INT2, INT4] * [100%,50%,25%,12.5%] | . | ZCU104-BISMO | [INT2, INT4] * [100%,50%,25%,12.5%] | . GPU | TX2-maxn | [FP16, FP32] * [100%,50%,25%,12.5%] | . | TX2-maxp | [FP16, FP32] * [100%,50%,25%,12.5%] | . | TX2-maxq | [FP16, FP32] * [100%,50%,25%,12.5%] | . TPU | TPU-fast clk | na | . | TPU-slow clk | na | . VLIW | NCS | [FP16] * [100%,50%,25%,12.5%] | . CPU | U96-Quadcore A53 | [INT2, INT4] * [100%,50%,25%,12.5%] | . ImageNet Classification . Hardware Platform ResNet50 GoogLeNetV1 MobileNet . FPGA | ZCU102-DPU | [INT8]*[100%,80%,50%,30%] | INT8 | na | . | ZCU104-DPU | INT8 | INT8 | na | . | Ultra96-DPU | [INT8]*[100%,80%,50%,30%] | INT8 | INT8 | . | ZCU104-FINN | na | na | na | . | ZCU104-BISMO | na | na | na | . GPU | TX2-maxn | FP16,FP32 | FP16,FP32 | na | . | TX2-maxp | FP16,FP32 | FP16,FP32 | na | . | TX2-maxq | FP16,FP32 | FP16,FP32 | na | . TPU | TPU-fast clk | na | INT8 | INT8 | . | TPU-slow clk | na | INT8 | INT8 | . VLIW | NCS | FP16 | na | na | . CPU | U96-Quadcore A53 | na | na | na | .",
            "url": "https://rcl-lab.github.io/Qutibench_Web/2020/04/30/Overview_of_experiments.html",
            "relUrl": "/2020/04/30/Overview_of_experiments.html",
            "date": " • Apr 30, 2020"
        }
        
    
  
    
        ,"post1": {
            "title": "Notebook to process and clean csv's",
            "content": "import pandas as pd import numpy as np import altair as alt import csv . Performance Predictions for mnist, cifar10 and imagenet - Heatmaps . Read csv &gt; process data &gt; save to another csv . ## Calculate the Arithmetic intensity (x axis) for each NN based on Fwd ops and Total params i=0.1 n_bytes=1 calc_arith = lambda operations, params, n_bytes: operations/(params*n_bytes) for index, row in df_topology.iterrows(): #nditer is a iterator object arith_intens = calc_arith(row[&#39;Fwd Ops&#39;], row[&#39;Total Params&#39;], n_bytes) #calculate the arith intensity with the lambda function df_topology.at[index, &#39;arith_intens&#39;] = arith_intens #saving it to the dataframe #to duplicate the dataframe so each row with (Platform, arith_intens) will be filled with 100 and then 0s to plot the vertical line later df_topology = pd.concat([df_topology, df_topology]) df_topology = pd.concat([df_topology, df_topology]) df_topology = df_topology.drop(columns=[&#39;Total Params&#39;,&#39;Fwd Ops&#39;]) #deleting unnecessary columns (Fwd ops and Total params) . ## Preparing the NNs dataset to be ploted as vertical lines later # creating a y list [100,100,100,100....0.0001,0.0001,0.0001...] to plot a vertical line later df_topology[&#39;performance&#39;] = [100] * round((len(df_topology.index))/4) + [25] * round((len(df_topology.index))/4) + [75] * round((len(df_topology.index))/4) +[0.000001] * round((len(df_topology.index))/4) . ## Calculating the rooflines (y axis) for each hardware platform (dataframe = df_topology + df) #--Calculating the values to plot for the roofline model-- maxX=160000 x_axis = np.arange(0.1,maxX,1) #to create a list that represents the x axis with numbers between 0 and 1000 dataframe = pd.DataFrame(columns=[&#39;Name&#39;,&#39;arith_intens&#39;,&#39;performance&#39;]) for index, row in df.iterrows(): #nditer is a iterator object dataframe = dataframe.append([pd.Series([df.at[index,&#39;Name&#39;],1,row[&#39;Bandwidth&#39;] ],dataframe.columns)], ignore_index=True) for i in np.nditer(x_axis): point = row[&#39;Bandwidth&#39;] * i if point &gt; row[&#39;Peak_Performance&#39;]: dataframe = dataframe.append([pd.Series([df.at[index,&#39;Name&#39;],i,row[&#39;Peak_Performance&#39;]],dataframe.columns)], ignore_index=True) dataframe = dataframe.append([pd.Series([df.at[index,&#39;Name&#39;],maxX, df.at[index,&#39;Peak_Performance&#39;]],dataframe.columns)], ignore_index=True) break . ## Merging NNs dataset with Hardware Platforms dataset dataframe = pd.concat([dataframe,df_topology]) . dataframe.to_csv(&#39;data/processed_csv/rooflines_hardware_neural_networks.csv&#39;, index = False) .",
            "url": "https://rcl-lab.github.io/Qutibench_Web/2020/04/29/process_data_save_csv.html",
            "relUrl": "/2020/04/29/process_data_save_csv.html",
            "date": " • Apr 29, 2020"
        }
        
    
  
    
        ,"post2": {
            "title": "Contributing",
            "content": "Add a Machine Learning Benchmark . Steps on how to add your favorite machine learning benchmark . Copy the file data/data_template.csv file and rename it with the name of your machine learning benchmark, e.g. data/imagenet.csv. . | Enter your data in this new .csv file, leaving columns blank if data is not available . | Copy 2020-01-01-Jupyter_benchmark_template.ipynb and rename it in the format yyyy-mm-dd-benchmark_name.ipynb e.g. 2020-01-01-imagenet.ipynb. . | Using jupyter Notebook/Lab, open the new notebook. Update the metadata in the first cell, (categories, title, subtitle) as well as the csv_path variable to point to your new data. If you would like to add an image, include it in the images/ folder of the repo and include a link in the metadata under the image field. . | Run all cells of the notebook (there&#39;s a shortcut for this) and ensure that all plots are displaying as they should. . | Commit your new work in git, and push/open a pull request in the repository. Once changes are merged they will go live on the website within a few minutes. . |",
            "url": "https://rcl-lab.github.io/Qutibench_Web/contributing/meta/2020/04/09/Contributing.html",
            "relUrl": "/contributing/meta/2020/04/09/Contributing.html",
            "date": " • Apr 9, 2020"
        }
        
    
  
    
        ,"post3": {
            "title": "Theoretical Analysis",
            "content": "Introduction . This webpage presents the Theoretical analysis. Lorem ipsum.. . Tables . Tables for Topologies . These tables show... . Tables for Platforms . These tables show... . Overview of Theoretical Evaluation . link to: . Rooflines for all Hardware Platforms and CNNs . This plot shows the Theoretical Rooflines for all hardware platforms... . Performance Prediction . Next plots will show the input per second of each network topology for each hardware platform... . MNIST . ImageNet . CIFAR .",
            "url": "https://rcl-lab.github.io/Qutibench_Web/jupyter/2020/04/02/Theoretical_Analysis.html",
            "relUrl": "/jupyter/2020/04/02/Theoretical_Analysis.html",
            "date": " • Apr 2, 2020"
        }
        
    
  
    
        ,"post4": {
            "title": "MNIST Performance",
            "content": "Theoretical Analysis of MNIST . Rooflines . Combining application requirements with hardware platform characteristics can be leveraged for performance predictions using UCB’s roofline models. Using assumptions for where weights, activation tensors, and state of a neural network are stored, combined with the size of the datatypes used, allow us to derive the arithmetic intensity of a neural network during inference. Combined with the roofline for a given hardware platform, we can provide insight as to whether a neural network will be memory or compute bound and guidance for what is theoretically possible in regards to its throughput. . Performance Prediction . The plot below shows ... Lorem Ipsum ... . Experimental Data Analysis . Overview of All Measurements for MNIST . MNIST Classification . Hardware Platform MLP . FPGA | ZCU102-DPU | na | . | ZCU104-DPU | na | . | Ultra96-DPU | na | . | ZCU104-FINN | [INT2, INT4] * [100%,50%,25%,12.5%] | . | ZCU104-BISMO | [INT2, INT4] * [100%,50%,25%,12.5%] | . GPU | TX2-maxn | [FP16, FP32] * [100%,50%,25%,12.5%] | . | TX2-maxp | [FP16, FP32] * [100%,50%,25%,12.5%] | . | TX2-maxq | [FP16, FP32] * [100%,50%,25%,12.5%] | . TPU | TPU-fast clk | na | . | TPU-slow clk | na | . VLIW | NCS | [FP16] * [100%,50%,25%,12.5%] | . CPU | U96-Quadcore A53 | [INT2, INT4] * [100%,50%,25%,12.5%] | . Line Plot . Boxplots . Pareto Graphs . Measurements . batch/thread/stream lat-comp fps-system fps-comp tp-system tp-comp top1 top5 [%] BasePWR [W] IdlePWR [W] FullPwr [W] GOPS . count 278.000000 | 278.000000 | 96.000000 | 2.780000e+02 | 96.000000 | 96.000000 | 278.000000 | 0.0 | 278.000000 | 278.000000 | 278.000000 | 0.0 | . mean 51.384892 | 18.759926 | 2963.662979 | 2.317115e+05 | 7.171515 | 49.448766 | 97.995612 | NaN | 6.498417 | 10.462590 | 12.066345 | NaN | . std 91.601984 | 51.803819 | 2269.508205 | 6.030472e+05 | 11.967183 | 94.692496 | 0.649877 | NaN | 3.743128 | 5.143244 | 4.489418 | NaN | . min 1.000000 | 0.002000 | 218.893000 | 1.972737e+01 | 0.043066 | 0.084298 | 96.850000 | NaN | 0.530000 | 1.200000 | 1.548000 | NaN | . 25% 4.000000 | 0.285652 | 482.129500 | 1.497902e+03 | 0.675684 | 2.056717 | 97.440000 | NaN | 1.800000 | 4.700000 | 9.229500 | NaN | . 50% 16.000000 | 1.235414 | 2894.530000 | 7.756988e+03 | 2.221820 | 9.825080 | 98.040000 | NaN | 9.200000 | 14.200000 | 14.358750 | NaN | . 75% 64.000000 | 8.630318 | 5132.930000 | 1.133818e+05 | 8.314235 | 48.249050 | 98.620000 | NaN | 9.200000 | 14.300000 | 15.347606 | NaN | . max 512.000000 | 435.264000 | 6360.250000 | 3.849624e+06 | 49.608700 | 517.656000 | 98.860000 | NaN | 9.200000 | 14.300000 | 15.775000 | NaN | .",
            "url": "https://rcl-lab.github.io/Qutibench_Web/l3/performance/mnist/2020/03/25/MNIST.html",
            "relUrl": "/l3/performance/mnist/2020/03/25/MNIST.html",
            "date": " • Mar 25, 2020"
        }
        
    
  
    
        ,"post5": {
            "title": "ImageNet Performance",
            "content": "Theoretical Analysis of ImageNet . Rooflines . Combining application requirements with hardware platform characteristics can be leveraged for performance predictions using UCB’s roofline models. Using assumptions for where weights, activation tensors, and state of a neural network are stored, combined with the size of the datatypes used, allow us to derive the arithmetic intensity of a neural network during inference. Combined with the roofline for a given hardware platform, we can provide insight as to whether a neural network will be memory or compute bound and guidance for what is theoretically possible in regards to its throughput. . Performance Prediction . Experimental Data Analysis . Overview of All Measurements for MNIST . ImageNet Classification . Hardware Platform ResNet50 GoogLeNetV1 MobileNet . FPGA | ZCU102-DPU | [INT8]*[100%,80%,50%,30%] | INT8 | na | . | ZCU104-DPU | INT8 | INT8 | na | . | Ultra96-DPU | [INT8]*[100%,80%,50%,30%] | INT8 | INT8 | . | ZCU104-FINN | na | na | na | . | ZCU104-BISMO | na | na | na | . GPU | TX2-maxn | FP16,FP32 | FP16,FP32 | na | . | TX2-maxp | FP16,FP32 | FP16,FP32 | na | . | TX2-maxq | FP16,FP32 | FP16,FP32 | na | . TPU | TPU-fast clk | na | INT8 | INT8 | . | TPU-slow clk | na | INT8 | INT8 | . VLIW | NCS | FP16 | na | na | . CPU | U96-Quadcore A53 | na | na | na | . Line Plot . Boxplots . Pareto Graphs . Measurements . Lorem ipsum ... . batch/thread/stream lat-comp fps-system fps-comp tp-system tp-comp top1 top5 [%] BasePWR [W] IdlePWR [W] FullPwr [W] GOPS PruningFactor norm-lat-comp . count 108.000000 | 108.000000 | 108.000000 | 103.000000 | 108.000000 | 108.000000 | 108.000000 | 108.000000 | 108.000000 | 100.000000 | 108.000000 | 0.0 | 108.000000 | 108.000000 | . mean 14.509259 | 268.169789 | 85.634377 | 120.124102 | 429.990518 | 526.763382 | 71.327311 | 90.373770 | 5.152333 | 8.970120 | 13.537268 | NaN | 84.259259 | 0.084496 | . std 28.698398 | 796.349653 | 79.038255 | 122.346505 | 378.324824 | 432.906072 | 2.887991 | 1.483093 | 6.532648 | 8.976935 | 11.391941 | NaN | 30.492950 | 0.192479 | . min 1.000000 | 2.570470 | 16.936600 | 17.756000 | 98.644084 | 112.536576 | 66.928000 | 87.705800 | 0.253000 | 0.253000 | 0.462000 | NaN | 12.500000 | 0.001783 | . 25% 2.000000 | 22.021050 | 37.291575 | 38.438350 | 180.599256 | 185.100699 | 69.410000 | 89.260000 | 1.800000 | 4.700000 | 8.239317 | NaN | 100.000000 | 0.006964 | . 50% 5.000000 | 68.489050 | 59.201100 | 66.848600 | 282.710500 | 405.891000 | 72.530000 | 90.850000 | 2.500000 | 6.800000 | 8.361605 | NaN | 100.000000 | 0.018346 | . 75% 8.000000 | 176.938500 | 116.282250 | 144.322000 | 543.816500 | 819.351390 | 73.300000 | 91.400000 | 2.500000 | 6.800000 | 11.040000 | NaN | 100.000000 | 0.045650 | . max 128.000000 | 7019.100000 | 379.109000 | 544.702000 | 1496.035640 | 1704.920000 | 75.172000 | 92.118000 | 20.000000 | 29.000000 | 40.600000 | NaN | 100.000000 | 1.000000 | .",
            "url": "https://rcl-lab.github.io/Qutibench_Web/l3/performance/imagenet/2020/03/25/ImageNet.html",
            "relUrl": "/l3/performance/imagenet/2020/03/25/ImageNet.html",
            "date": " • Mar 25, 2020"
        }
        
    
  
    
        ,"post6": {
            "title": "CIFAR Performance",
            "content": "Theretical Analysis of CIFAR . Rooflines . Combining application requirements with hardware platform characteristics can be leveraged for performance predictions using UCB’s roofline models. Using assumptions for where weights, activation tensors, and state of a neural network are stored, combined with the size of the datatypes used, allow us to derive the arithmetic intensity of a neural network during inference. Combined with the roofline for a given hardware platform, we can provide insight as to whether a neural network will be memory or compute bound and guidance for what is theoretically possible in regards to its throughput. . Performance Prediction . The plot below shows... Lorem ipsum ... . Experimental Data Analysis . Overview of All Measurements for CIFAR . CIFAR10 Classification . Hardware Platform CNV . FPGA | ZCU102-DPU | na | . | ZCU104-DPU | na | . | Ultra96-DPU | na | . | ZCU104-FINN | [INT2,INT4]*[100%,50%,25%,12.5%] | . | ZCU104-BISMO | [INT2,INT4]*[100%,50%,25%,12.5%] | . GPU | TX2-maxn | [FP16,FP32]*[100%,50%,25%,12.5%] | . | TX2-maxp | [FP16,FP32]*[100%,50%,25%,12.5%] | . | TX2-maxq | [FP16,FP32]*[100%,50%,25%,12.5%] | . TPU | TPU-fast clk | na | . | TPU-slow clk | na | . VLIW | NCS | [FP16]*[100%,50%,25%,12.5%] | . CPU | U96-Quadcore A53 | [INT2,INT4]*[100%,50%,25%,12.5%] | . Line Plot . Boxplots . Pareto Graphs . Measurements . batch/thread/stream lat-comp fps-system fps-comp tp-system tp-comp top1 top5 [%] BasePWR [W] IdlePWR [W] FullPwr [W] GOPS PruningFactor norm-lat-comp . count 250.000000 | 250.000000 | 96.000000 | 250.000000 | 0.0 | 84.000000 | 250.000000 | 0.0 | 250.000000 | 180.000000 | 250.000000 | 69.000000 | 250.000000 | 250.000000 | . mean 215.136000 | 115.574116 | 1370.634500 | 7263.292764 | NaN | 630.798860 | 81.625760 | NaN | 6.195840 | 7.275000 | 11.461902 | 87.743052 | 40.750000 | 0.007937 | . std 1254.239246 | 929.346956 | 1073.314636 | 11779.292212 | NaN | 484.599296 | 4.429825 | NaN | 3.830652 | 4.196778 | 4.967402 | 564.591429 | 31.006582 | 0.063824 | . min 1.000000 | 0.072000 | 151.555000 | 58.596039 | NaN | 96.317001 | 73.640000 | NaN | 0.530000 | 1.200000 | 1.560000 | 0.008018 | 12.500000 | 0.000005 | . 25% 4.000000 | 1.943957 | 414.847250 | 560.290906 | NaN | 270.065261 | 77.820000 | NaN | 1.800000 | 4.700000 | 7.400000 | 0.475691 | 12.500000 | 0.000134 | . 50% 16.000000 | 8.341500 | 1055.140000 | 1375.970000 | NaN | 462.443938 | 83.250000 | NaN | 9.200000 | 4.700000 | 13.500000 | 1.952694 | 25.000000 | 0.000573 | . 75% 64.000000 | 41.920450 | 2301.155000 | 9689.250000 | NaN | 908.052096 | 85.550000 | NaN | 9.200000 | 11.500000 | 14.825000 | 15.022391 | 50.000000 | 0.002879 | . max 10000.000000 | 14561.129000 | 3631.210000 | 60757.090000 | NaN | 2025.226995 | 88.420000 | NaN | 9.200000 | 12.000000 | 21.357500 | 4694.497280 | 100.000000 | 1.000000 | .",
            "url": "https://rcl-lab.github.io/Qutibench_Web/l3/performance/cifar/2020/03/25/CIFAR.html",
            "relUrl": "/l3/performance/cifar/2020/03/25/CIFAR.html",
            "date": " • Mar 25, 2020"
        }
        
    
  
    
        ,"post7": {
            "title": "Initial Data Analysis",
            "content": "Organize . Figure 25 . Note: Don&#39;t have data for left side and missing int4/int2 data for fpga Original: . . maxp_df[&quot;hw_quant_prun&quot;] = maxp_df.apply(lambda r: &quot;_&quot;.join([r.HWType, r.Precision, r.PruningFactor]), axis=1) . mlp_df = maxp_df[(maxp_df[&quot;NN_Topology&quot;] == &quot;MLP&quot;)] . mlp_df[&quot;hw_quant_prun&quot;] = mlp_df.apply(lambda r: &quot;_&quot;.join([r.HWType, r.Precision, r.PruningFactor]), axis=1) . figa_df = mlp_df[(mlp_df[&quot;HWType&quot;].isin([&quot;NCS&quot;, &quot;ZCU104-Bismo&quot;, &quot;A53-gemmlowp&quot;]))] figb_df = mlp_df[(mlp_df[&quot;HWType&quot;].isin([&quot;GPU&quot;, &quot;ZCU104-FINN&quot;, &quot;A53-gemmlowp&quot;]))] . def select_color(sel, column): return alt.condition(sel, alt.Color(column), alt.value(&#39;lightgray&#39;)) . fig25s = [] fig25_dfs = [figa_df, figb_df] for df in fig25_dfs: sel = alt.selection_multi(fields=[&quot;hw_quant_prun&quot;], bind=&quot;legend&quot;) fig25_dot = alt.Chart(df).mark_point().encode( x=&#39;lat-comp&#39;, y=alt.Y(&#39;fps-comp&#39;, scale=alt.Scale(type=&quot;log&quot;)), color=select_color(sel, &#39;hw_quant_prun:N&#39;), tooltip=[&#39;fps-comp&#39;, &#39;lat-comp&#39;, &#39;HWType&#39;, &#39;batch/thread/stream&#39;], ) fig25_line = alt.Chart(df).mark_line().encode( x=&#39;lat-comp&#39;, y=&#39;fps-comp&#39;, color=select_color(sel, &#39;hw_quant_prun:N&#39;), tooltip=[&#39;fps-comp&#39;, &#39;lat-comp&#39;, &#39;HWType&#39;, &#39;batch/thread/stream&#39;], ) fig = (fig25_dot+fig25_line).properties( title=&quot;Latency versus Performance for Pruned and Quantized MLP Variants&quot;, width=W/len(fig25_dfs), height=H, ).add_selection(sel).interactive() fig25s.append(fig) alt.hconcat(*fig25s) . maxp_df[&quot;quant_model&quot;] = maxp_df.Precision + &#39;_&#39; + maxp_df.HWType . def norm_by_group(df, column, group_col): df[&quot;norm-&quot;+column] = df.groupby(group_col)[column].apply(lambda x: (x / x.max())) return df . norm_by_group(maxp_df, &quot;lat-comp&quot;, &quot;NN_Topology&quot;); . cnv_df = maxp_df[(maxp_df.NN_Topology == &#39;CNV&#39;) &amp; maxp_df[&#39;norm-lat-comp&#39;].notna()] fig = sns.boxplot(x=&quot;quant_model&quot;, y=&quot;norm-lat-comp&quot;, hue=&quot;PruningFactor&quot;, data=cnv_df) fig.set_title(&quot;latency by chip and net pruning for CNV&quot;) plt.yscale(&quot;log&quot;) plt.xticks(rotation=45) . TODO:get log axis working for grouped bar . cnv_df[&quot;pf&quot;] = cnv_df.PruningFactor.str.strip(&#39;%&#39;).astype(float) . box1 = alt.Chart(cnv_df).mark_boxplot().encode( x=&#39;pf:O&#39;, y=alt.Y(&quot;norm-lat-comp&quot;, scale=alt.Scale(type=&quot;log&quot;)), color=&#39;pf:O&#39; ).facet(column=&quot;quant_model&quot;).properties( title=&quot;Latency by Hardware/Framework and Pruning for CNV&quot; ).interactive() box1 . fig = sns.boxplot(x=&quot;quant_model&quot;, y=&quot;fps-comp&quot;, hue=&quot;PruningFactor&quot;, data=maxp_df[(maxp_df.NN_Topology == &#39;CNV&#39;) &amp; maxp_df[&quot;fps-comp&quot;].notna()]) fig.set_title(&quot;fig 13: FPS by chip and net pruning (CNV)&quot;) plt.yscale(&quot;log&quot;) plt.xticks(rotation=45) . Paretos . mnist_df = maxp_df[(maxp_df.NN_Topology == &#39;MLP&#39;) &amp; maxp_df[&quot;top1 [%]&quot;].notna()] cifar_df = maxp_df[(maxp_df.NN_Topology == &#39;CNV&#39;) &amp; maxp_df[&quot;top1 [%]&quot;].notna()] imagenet_df = maxp_df[maxp_df.NN_Topology.isin([&#39;GNv1&#39;,&#39;RN50&#39;,&#39;MNv1&#39;]) &amp; maxp_df[&quot;top1 [%]&quot;].notna()] . bad_precisions = [&quot;FP&quot;+str(i) for i in range(17,24)] imagenet_df.Precision = imagenet_df.Precision.apply(lambda x: &#39;FP16&#39; if x in bad_precisions else x) . %%writefile utils.py def get_pareto_df(df, groupcol, xcol, ycol): pareto_line_df = df.groupby(groupcol)[xcol].max().to_frame(&quot;x&quot;) pareto_line_df[&#39;y&#39;] = df.groupby(groupcol)[ycol].agg(lambda x: x.value_counts().index[0]) pareto_line_df.sort_values(&#39;y&#39;, ascending=False, inplace=True) pareto_line_df[&#39;x&#39;] = pareto_line_df.x.cummax() pareto_line_df.drop_duplicates(&#39;x&#39;, keep=&#39;first&#39;, inplace=True) pareto_line_df[&#39;group&#39;] = pareto_line_df.index return pareto_line_df def label_point(x, y, val, ax, rot=0): &quot;&quot;&quot; from https://stackoverflow.com/questions/46027653/adding-labels-in-x-y-scatter-plot-with-seaborn&quot;&quot;&quot; a = pd.concat({&#39;x&#39;: x, &#39;y&#39;: y, &#39;val&#39;: val}, axis=1) for i, point in a.iterrows(): ax.text(point[&#39;x&#39;]+.02, point[&#39;y&#39;], str(point[&#39;val&#39;]), rotation=rot) . MNIST . sns.set(font_scale=0.8) mnist_pareto = get_pareto_df(mnist_df, &#39;hw_quant_prun&#39;, &#39;fps-comp&#39;, &#39;top1 [%]&#39;) fig, ax = plt.subplots() sns.lineplot(x=&#39;x&#39;, y=&#39;y&#39;, data=mnist_pareto, ax=ax, label=&quot;Pareto Frontier&quot;) ax.lines[0].set_linestyle(&quot;--&quot;) sns.lineplot(x=&#39;fps-comp&#39;, y=&#39;top1 [%]&#39;, hue=&#39;hw_quant_prun&#39;, data=mnist_df, ax=ax) sns.scatterplot(x=&#39;fps-comp&#39;, y=&#39;top1 [%]&#39;, hue=&#39;hw_quant_prun&#39;, data=mnist_df, ax=ax, legend=False) plt.title(&quot;MNIST Cassification Design Space: Accuracy versus Performance&quot;) plt.xlabel(&#39;FPS [hz]&#39;) plt.ylabel(&#39;Top1 Accuracy [%]&#39;) plt.legend(loc=&quot;upper right&quot;, ncol=4) plt.ylim([96, 102]) plt.xlim([-100000, 4800000]) label_point(mnist_pareto.x, mnist_pareto.y, mnist_pareto.group, plt.gca(), 35) . mnist_df.rename(columns={&quot;top1 [%]&quot;: &quot;top1&quot;}, inplace=True) . mnist_lines = alt.Chart(mnist_df).mark_line(point=True).encode( x=&quot;fps-comp&quot;, y=alt.Y(&quot;top1:Q&quot;, scale=alt.Scale(zero=False)), color=alt.Color(&quot;hw_quant_prun&quot;, legend=alt.Legend(columns=2)), tooltip=[&quot;HWType&quot;, &quot;Precision&quot;, &quot;PruningFactor&quot;, &quot;batch/thread/stream&quot;, &quot;top1&quot;, &quot;fps-comp&quot;], ) mnist_pareto_plot = alt.Chart(mnist_pareto).mark_line().encode( x=&quot;x&quot;, y=alt.Y(&quot;y&quot;, scale=alt.Scale(zero=False)), ) (mnist_lines+mnist_pareto_plot).interactive().properties( width=W, height=H, title=&quot;MNIST Cassification Design Space: Accuracy versus Performance&quot; ) . CIFAR . Original: . cifar_pareto = get_pareto_df(cifar_df, &#39;hw_quant_prun&#39;, &#39;fps-comp&#39;, &#39;top1 [%]&#39;) fig, ax = plt.subplots() sns.lineplot(x=&#39;x&#39;, y=&#39;y&#39;, data=cifar_pareto, ax=ax, label=&quot;Pareto Frontier&quot;) ax.lines[0].set_linestyle(&quot;--&quot;) sns.lineplot(x=&#39;fps-comp&#39;, y=&#39;top1 [%]&#39;, hue=&#39;hw_quant_prun&#39;, data=cifar_df, ax=ax) sns.scatterplot(x=&#39;fps-comp&#39;, y=&#39;top1 [%]&#39;, hue=&#39;hw_quant_prun&#39;, data=cifar_df, ax=ax, legend=False) plt.title(&quot;CIFAR 10 Classification Design Space: Accuracy versus Performance&quot;) plt.xlabel(&#39;FPS [hz]&#39;) plt.ylabel(&#39;Top1 Accuracy [%]&#39;) plt.ylim([73, 98]) plt.xlim([0, 80000]) plt.legend(loc=&quot;upper right&quot;, ncol=3) label_point(cifar_pareto.x, cifar_pareto.y, cifar_pareto.group, plt.gca(), 30) . cifar_df.rename(columns={&quot;top1 [%]&quot;: &quot;top1&quot;}, inplace=True) cifar_lines = alt.Chart(cifar_df).mark_line(point=True).encode( x=&quot;fps-comp&quot;, y=alt.Y(&quot;top1:Q&quot;, scale=alt.Scale(zero=False)), color=alt.Color(&quot;hw_quant_prun&quot;, legend=alt.Legend(columns=1)), tooltip=[&quot;HWType&quot;, &quot;Precision&quot;, &quot;PruningFactor&quot;, &quot;batch/thread/stream&quot;, &quot;top1&quot;, &quot;fps-comp&quot;], ) cifar_pareto_plot = alt.Chart(cifar_pareto).mark_line().encode( x=&quot;x&quot;, y=alt.Y(&quot;y&quot;, scale=alt.Scale(zero=False)), ) (cifar_lines+cifar_pareto_plot).interactive().properties( width=W, height=H, title=&quot;CIFAR Cassification Design Space: Accuracy versus Performance&quot; ) . imagenet_df[&quot;hw_precision_net_prun&quot;] = imagenet_df.apply(lambda r: &quot;_&quot;.join([r.HWType, r.Precision, r.NN_Topology, r.PruningFactor]), axis=1) . imagenet_pareto = get_pareto_df(imagenet_df, &#39;hw_precision_net_prun&#39;, &#39;fps-comp&#39;, &#39;top1 [%]&#39;) fig, ax = plt.subplots() sns.lineplot(x=&#39;x&#39;, y=&#39;y&#39;, data=imagenet_pareto, ax=ax, label=&quot;Pareto Frontier&quot;) ax.lines[0].set_linestyle(&quot;--&quot;) sns.lineplot(x=&#39;fps-comp&#39;, y=&#39;top1 [%]&#39;, hue=&#39;hw_precision_net_prun&#39;, data=imagenet_df, ax=ax) sns.scatterplot(x=&#39;fps-comp&#39;, y=&#39;top1 [%]&#39;, hue=&#39;hw_precision_net_prun&#39;, data=imagenet_df, ax=ax, legend=False) plt.title(&quot;ImageNet Classification Design Space: Accuracy versus Performance&quot;) plt.xlabel(&#39;FPS [hz]&#39;) plt.ylabel(&#39;Top1 Accuracy [%]&#39;) plt.ylim([66, 79]) plt.xlim([0, 750]) plt.legend(loc=&quot;upper right&quot;, ncol=2) label_point(imagenet_pareto.x, imagenet_pareto.y, imagenet_pareto.group, plt.gca(), 15) . imagenet_df.rename(columns={&quot;top1 [%]&quot;: &quot;top1&quot;}, inplace=True) imagenet_lines = alt.Chart(imagenet_df).mark_line(point=True).encode( x=&quot;fps-comp&quot;, y=alt.Y(&quot;top1:Q&quot;, scale=alt.Scale(zero=False)), color=alt.Color(&quot;hw_precision_net_prun&quot;, legend=alt.Legend(columns=1)), tooltip=[&quot;HWType&quot;, &quot;Precision&quot;, &quot;PruningFactor&quot;, &quot;batch/thread/stream&quot;, &quot;top1&quot;, &quot;fps-comp&quot;], ) imagenet_pareto_plot = alt.Chart(imagenet_pareto).mark_line().encode( x=&quot;x&quot;, y=alt.Y(&quot;y&quot;, scale=alt.Scale(zero=False)), ) (imagenet_lines+imagenet_pareto_plot).interactive().properties( width=W, height=H, title=&quot;ImageNet Cassification Design Space: Accuracy versus Performance&quot; ) .",
            "url": "https://rcl-lab.github.io/Qutibench_Web/jupyter/2020/03/13/Convert-to-Altair.html",
            "relUrl": "/jupyter/2020/03/13/Convert-to-Altair.html",
            "date": " • Mar 13, 2020"
        }
        
    
  
    
        ,"post8": {
            "title": "Performance Template Notebook",
            "content": "TODO . Remove cells that filter dataframe | Rename dataframe and only use one | Break up original 3 benchmarks data | Add requirements.txt file | . Rooflines . L3 Performance . Table Statistics . batch/thread/stream lat-comp fps-system fps-comp tp-system tp-comp top1 top5 [%] BasePWR [W] IdlePWR [W] FullPwr [W] GOPS . count 278.000000 | 278.000000 | 96.000000 | 2.780000e+02 | 96.000000 | 96.000000 | 278.000000 | 0.0 | 278.000000 | 278.000000 | 278.000000 | 0.0 | . mean 51.384892 | 18.759926 | 2963.662979 | 2.317115e+05 | 7.171515 | 49.448766 | 97.995612 | NaN | 6.498417 | 10.462590 | 12.066345 | NaN | . std 91.601984 | 51.803819 | 2269.508205 | 6.030472e+05 | 11.967183 | 94.692496 | 0.649877 | NaN | 3.743128 | 5.143244 | 4.489418 | NaN | . min 1.000000 | 0.002000 | 218.893000 | 1.972737e+01 | 0.043066 | 0.084298 | 96.850000 | NaN | 0.530000 | 1.200000 | 1.548000 | NaN | . 25% 4.000000 | 0.285652 | 482.129500 | 1.497902e+03 | 0.675684 | 2.056717 | 97.440000 | NaN | 1.800000 | 4.700000 | 9.229500 | NaN | . 50% 16.000000 | 1.235414 | 2894.530000 | 7.756988e+03 | 2.221820 | 9.825080 | 98.040000 | NaN | 9.200000 | 14.200000 | 14.358750 | NaN | . 75% 64.000000 | 8.630318 | 5132.930000 | 1.133818e+05 | 8.314235 | 48.249050 | 98.620000 | NaN | 9.200000 | 14.300000 | 15.347606 | NaN | . max 512.000000 | 435.264000 | 6360.250000 | 3.849624e+06 | 49.608700 | 517.656000 | 98.860000 | NaN | 9.200000 | 14.300000 | 15.775000 | NaN | . Line Plot . Boxplots . Pareto .",
            "url": "https://rcl-lab.github.io/Qutibench_Web/2020/01/01/Jupyter_benchmark_template.html",
            "relUrl": "/2020/01/01/Jupyter_benchmark_template.html",
            "date": " • Jan 1, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About This Work",
          "content": ". QuTiBench . Neural Networks have become one of the most successful universal machine learning algorithms. They play a key role in enabling machine vision and speech recognition, and are increasingly adopted in other application domains. While the underlying computation is structurally simple, their computational complexity is enormous and comes along with equally challenging memory requirements both in regards to capacity and access bandwidth. This limits deployment in particular within energy constrained, embedded environments. In order to address these implementation challenges, a broad spectrum of new customized and heterogeneous hardware architectures have emerged, sometime referred to as deep learning processing units, often accompanied with co-designed algorithms to extract maximum benefit out of the hardware. Furthermore, numerous optimization techniques are being explored to reduce compute and memory requirements while maintaining accuracy. This results in an abundance of algorithmic and architectural choices, some of which fit specific use cases better than others. . For system level designers, there is currently no good way to compare the variety of hardware, algorithm and optimization options. While there are many benchmarking efforts in this field, they cover only subsections of the embedded design space. None of the existing benchmarks support essential algorithmic optimizations such as quantization, an important technique to stay on chip, or specialized heterogeneous hardware architectures. We propose a novel benchmark suite, named QuTiBench, that addresses this need. QuTiBench is a novel multi-tiered benchmarking methodology that supports algorithmic optimizations such as quantization and helps system developers understand the benefits and limitations of these novel compute architectures in regards to specific neural networks and will help drive future innovation. We invite the community to contribute to QuTiBench in order to be able to support the full spectrum of choices in implementing machine learning systems. . Contributing . See the website for instructions on contributing. .",
          "url": "https://rcl-lab.github.io/Qutibench_Web/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://rcl-lab.github.io/Qutibench_Web/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}